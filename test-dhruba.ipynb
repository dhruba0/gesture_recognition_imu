{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2f5710",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-08-18T13:12:20.356534Z",
     "iopub.status.busy": "2025-08-18T13:12:20.356271Z",
     "iopub.status.idle": "2025-08-18T13:12:22.664358Z",
     "shell.execute_reply": "2025-08-18T13:12:22.663538Z"
    },
    "papermill": {
     "duration": 2.316656,
     "end_time": "2025-08-18T13:12:22.665626",
     "exception": false,
     "start_time": "2025-08-18T13:12:20.348970",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>gesture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEQ_000011</td>\n",
       "      <td>Eyelash - pull hair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence_id              gesture\n",
       "0  SEQ_000001   Cheek - pinch skin\n",
       "1  SEQ_000011  Eyelash - pull hair"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install -q colorednoise\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sub = pd.read_parquet('/kaggle/input/test-sub/submission (2).parquet')\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81cf861",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-18T13:12:22.677682Z",
     "iopub.status.busy": "2025-08-18T13:12:22.677339Z",
     "iopub.status.idle": "2025-08-18T13:12:32.631442Z",
     "shell.execute_reply": "2025-08-18T13:12:32.630771Z"
    },
    "papermill": {
     "duration": 9.961589,
     "end_time": "2025-08-18T13:12:32.632885",
     "exception": false,
     "start_time": "2025-08-18T13:12:22.671296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import colorednoise as cn\n",
    "import gc\n",
    "import librosa\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "from glob import glob\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.signal import butter, lfilter\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11cf1c2f",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-08-18T13:12:32.644485Z",
     "iopub.status.busy": "2025-08-18T13:12:32.644244Z",
     "iopub.status.idle": "2025-08-18T13:12:32.648113Z",
     "shell.execute_reply": "2025-08-18T13:12:32.647449Z"
    },
    "papermill": {
     "duration": 0.010667,
     "end_time": "2025-08-18T13:12:32.649284",
     "exception": false,
     "start_time": "2025-08-18T13:12:32.638617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    MIXUP_PROB = 0.5\n",
    "\n",
    "class paths:\n",
    "    TEST_CSV = \"/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv\"\n",
    "    TRAIN_CSV = \"/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a937d9d",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-08-18T13:12:32.659850Z",
     "iopub.status.busy": "2025-08-18T13:12:32.659625Z",
     "iopub.status.idle": "2025-08-18T13:12:32.666741Z",
     "shell.execute_reply": "2025-08-18T13:12:32.666101Z"
    },
    "papermill": {
     "duration": 0.013682,
     "end_time": "2025-08-18T13:12:32.667891",
     "exception": false,
     "start_time": "2025-08-18T13:12:32.654209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "    \n",
    "\n",
    "def sep():\n",
    "    print(\"—\"*100)\n",
    "\n",
    "label_to_num = {\n",
    "    'Above ear - pull hair': 0,  # < ------- TARGETS START\n",
    "    'Cheek - pinch skin': 1,\n",
    "    'Eyebrow - pull hair': 2,\n",
    "    'Eyelash - pull hair': 3,\n",
    "    'Forehead - pull hairline': 4,\n",
    "    'Forehead - scratch': 5,\n",
    "    'Neck - pinch skin': 6,\n",
    "    'Neck - scratch': 7,  # < ------- TARGETS END\n",
    "    'Drink from bottle/cup': 8,  # < ------- NON-TARGETS START\n",
    "    'Feel around in tray and pull out an object': 9,\n",
    "    'Glasses on/off': 10,\n",
    "    'Pinch knee/leg skin': 11,\n",
    "    'Pull air toward your face': 12,\n",
    "    'Scratch knee/leg skin': 13,\n",
    "    'Text on phone': 14,\n",
    "    'Wave hello': 15,\n",
    "    'Write name in air': 16,\n",
    "    'Write name on leg': 17  # < ------- NON-TARGETS END\n",
    "}\n",
    "\n",
    "num_to_label = {v: k for k, v in label_to_num.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4faf246d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:12:32.678760Z",
     "iopub.status.busy": "2025-08-18T13:12:32.678499Z",
     "iopub.status.idle": "2025-08-18T13:13:05.371094Z",
     "shell.execute_reply": "2025-08-18T13:13:05.370282Z"
    },
    "papermill": {
     "duration": 32.704685,
     "end_time": "2025-08-18T13:13:05.377584",
     "exception": false,
     "start_time": "2025-08-18T13:12:32.672899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataframe shape: (574945, 341)\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Tesat dataframe shape: (107, 336)\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(paths.TRAIN_CSV)\n",
    "df_test = pd.read_csv(paths.TEST_CSV)\n",
    "\n",
    "print(f\"Train dataframe shape: {df_train.shape}\"), sep()\n",
    "print(f\"Tesat dataframe shape: {df_test.shape}\"), sep()\n",
    "\n",
    "df_train[\"target\"] = df_train[\"gesture\"].map(label_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56315016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:05.389582Z",
     "iopub.status.busy": "2025-08-18T13:13:05.389325Z",
     "iopub.status.idle": "2025-08-18T13:13:06.537866Z",
     "shell.execute_reply": "2025-08-18T13:13:06.537192Z"
    },
    "papermill": {
     "duration": 1.156576,
     "end_time": "2025-08-18T13:13:06.539480",
     "exception": false,
     "start_time": "2025-08-18T13:13:05.382904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "demo = df_train[['sequence_id','target']].drop_duplicates()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_seq, val_seq, train_y, val_y = train_test_split(\n",
    "    demo['sequence_id'],               \n",
    "    demo['target'],              \n",
    "    test_size=0.20,   \n",
    "    train_size=None,  \n",
    "    random_state=42,  \n",
    "    shuffle=True,     \n",
    "    stratify=demo['target']      \n",
    ")\n",
    "\n",
    "# print(train_y.value_counts())\n",
    "# print(val_y.value_counts())\n",
    "\n",
    "train = df_train[df_train.sequence_id.isin(train_seq)]\n",
    "val = df_train[df_train.sequence_id.isin(val_seq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aece5000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.551988Z",
     "iopub.status.busy": "2025-08-18T13:13:06.551310Z",
     "iopub.status.idle": "2025-08-18T13:13:06.558305Z",
     "shell.execute_reply": "2025-08-18T13:13:06.557504Z"
    },
    "papermill": {
     "duration": 0.014636,
     "end_time": "2025-08-18T13:13:06.559618",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.544982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def standard_scale(arr: np.ndarray) -> np.ndarray:\n",
    "    means = np.nanmean(arr, axis=0)\n",
    "    stds = np.nanstd(arr, axis=0)\n",
    "    stds = np.where(stds == 0, 1, stds)  # Prevent division by zero for constant columns\n",
    "    scaled = (arr - means) / stds\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def random_padding(x,max_time_steps= 100):\n",
    "    ##assuming seq shape is time_steps x 7 (imu only)\n",
    "    x= np.array(x)\n",
    "    if x.shape[0] < max_time_steps:\n",
    "        r = torch.randint(0,max_time_steps - x.shape[0], size = (1,))\n",
    "        final_x = np.vstack((torch.zeros(r,x.shape[1]),x,torch.zeros(max_time_steps-r-x.shape[0],x.shape[1])))\n",
    "        assert final_x.shape[0] == max_time_steps, \"Error: Shape issue in padding!!\"\n",
    "        # final_x = pd.DataFrame(final_x)\n",
    "        # final_x.columns = x.columns\n",
    "        return final_x\n",
    "    else:\n",
    "        return  x[:max_time_steps]\n",
    "\n",
    "\n",
    "imu_cols = [\"acc_x\", \"acc_y\", \"acc_z\", \"rot_w\", \"rot_x\", \"rot_y\", \"rot_z\"]\n",
    "# train_X, train_y = [], []\n",
    "\n",
    "# for sequence_id in tqdm(train_seq):\n",
    "#     ds = train[train[\"sequence_id\"] == sequence_id]\n",
    "#     X = ds[imu_cols].values\n",
    "#     y = ds.target.values[0]\n",
    "#     acc = standard_scale(X[:, 0:3])\n",
    "#     rot = X[:, 3:]\n",
    "#     X = np.concatenate([acc, rot], axis=1)\n",
    "#     X = np.where(np.isnan(X), 0, X)  # fill NaNs\n",
    "#     train_X.append(X)\n",
    "#     train_y.append(y)\n",
    "\n",
    "# train_y = np.array(train_y)\n",
    "\n",
    "# val_X, val_y = [], []\n",
    "\n",
    "# for sequence_id in tqdm(val_seq):\n",
    "#     ds = val[val[\"sequence_id\"] == sequence_id]\n",
    "#     X = ds[imu_cols].values\n",
    "#     y = ds.target.values[0]\n",
    "#     acc = standard_scale(X[:, 0:3])\n",
    "#     rot = X[:, 3:]\n",
    "#     X = np.concatenate([acc, rot], axis=1)\n",
    "#     X = np.where(np.isnan(X), 0, X)  # fill NaNs\n",
    "#     val_X.append(X)\n",
    "#     val_y.append(y)\n",
    "\n",
    "# val_y = np.array(val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d2aed08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.570729Z",
     "iopub.status.busy": "2025-08-18T13:13:06.570489Z",
     "iopub.status.idle": "2025-08-18T13:13:06.582431Z",
     "shell.execute_reply": "2025-08-18T13:13:06.581466Z"
    },
    "papermill": {
     "duration": 0.018951,
     "end_time": "2025-08-18T13:13:06.583720",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.564769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 574.52it/s]\n"
     ]
    }
   ],
   "source": [
    "test_X = []\n",
    "sequence_ids_test = df_test.sequence_id.unique()\n",
    "\n",
    "for sequence_id in tqdm(sequence_ids_test):\n",
    "    ds = df_test[df_test[\"sequence_id\"] == sequence_id]\n",
    "    X = ds[imu_cols].values\n",
    "    acc = standard_scale(X[:, 0:3])\n",
    "    rot = X[:, 3:]\n",
    "    X = np.concatenate([acc, rot], axis=1)\n",
    "    X = np.where(np.isnan(X), 0, X)  # fill NaNs\n",
    "    test_X.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "484f14dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.595420Z",
     "iopub.status.busy": "2025-08-18T13:13:06.595212Z",
     "iopub.status.idle": "2025-08-18T13:13:06.601488Z",
     "shell.execute_reply": "2025-08-18T13:13:06.600636Z"
    },
    "papermill": {
     "duration": 0.013451,
     "end_time": "2025-08-18T13:13:06.602748",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.589297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SignalTransform:\n",
    "    def __init__(self, always_apply: bool = False, p: float = 0.5):\n",
    "        self.always_apply = always_apply\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        if self.always_apply:\n",
    "            return self.apply(y)\n",
    "        else:\n",
    "            if np.random.rand() < self.p:\n",
    "                return self.apply(y)\n",
    "            else:\n",
    "                return y\n",
    "\n",
    "    def apply(self, y: np.ndarray):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self, transforms: list):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        for trns in self.transforms:\n",
    "            y = trns(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class OneOf:\n",
    "    def __init__(self, transforms: list):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        n_trns = len(self.transforms)\n",
    "        trns_idx = np.random.choice(n_trns)\n",
    "        trns = self.transforms[trns_idx]\n",
    "        return trns(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6319f45d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.614208Z",
     "iopub.status.busy": "2025-08-18T13:13:06.613515Z",
     "iopub.status.idle": "2025-08-18T13:13:06.618488Z",
     "shell.execute_reply": "2025-08-18T13:13:06.617949Z"
    },
    "papermill": {
     "duration": 0.011787,
     "end_time": "2025-08-18T13:13:06.619600",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.607813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GaussianNoise(SignalTransform):\n",
    "    def __init__(\n",
    "        self, always_apply: bool = False, \n",
    "        p: float = 0.5, max_noise_amplitude: float = 0.20, **kwargs\n",
    "    ):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.noise_amplitude = (0.0, max_noise_amplitude)\n",
    "\n",
    "    def apply(self, x: np.ndarray, **params):\n",
    "        noise_amplitude = np.random.uniform(*self.noise_amplitude)\n",
    "        noise = np.random.randn(*x.shape)  # shape (L, N)\n",
    "        augmented = (x + noise * noise_amplitude).astype(x.dtype)\n",
    "        return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9f36f5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.631943Z",
     "iopub.status.busy": "2025-08-18T13:13:06.631386Z",
     "iopub.status.idle": "2025-08-18T13:13:06.637128Z",
     "shell.execute_reply": "2025-08-18T13:13:06.636562Z"
    },
    "papermill": {
     "duration": 0.013138,
     "end_time": "2025-08-18T13:13:06.638256",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.625118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PinkNoiseSNR(SignalTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, min_snr=5.0, max_snr=20.0, **kwargs):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.min_snr = min_snr\n",
    "        self.max_snr = max_snr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        snr = np.random.uniform(self.min_snr, self.max_snr)\n",
    "        a_signal = np.sqrt((y ** 2).max(axis=0))  # shape: (N,)\n",
    "        a_noise = a_signal / (10 ** (snr / 20))   # shape: (N,)\n",
    "        pink_noise = np.stack([cn.powerlaw_psd_gaussian(1, len(y)) for _ in range(y.shape[1])], axis=1)\n",
    "        a_pink = np.sqrt((pink_noise ** 2).max(axis=0))  # shape: (N,)\n",
    "        pink_noise_normalized = pink_noise * (a_noise / a_pink)\n",
    "        augmented = (y + pink_noise_normalized).astype(y.dtype)\n",
    "        return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6da5a8b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.649388Z",
     "iopub.status.busy": "2025-08-18T13:13:06.649194Z",
     "iopub.status.idle": "2025-08-18T13:13:06.655595Z",
     "shell.execute_reply": "2025-08-18T13:13:06.654988Z"
    },
    "papermill": {
     "duration": 0.01334,
     "end_time": "2025-08-18T13:13:06.656784",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.643444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeStretch(SignalTransform):\n",
    "    def __init__(self, max_rate=1.5, min_rate=0.5, always_apply=False, p=0.5):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.max_rate = max_rate\n",
    "        self.min_rate = min_rate\n",
    "        self.always_apply = always_apply\n",
    "        self.p = p\n",
    "\n",
    "    def apply(self, x: np.ndarray):\n",
    "        \"\"\"\n",
    "        Stretch a 1D or 2D array in time using linear interpolation.\n",
    "        - x: np.ndarray of shape (L,) or (L, N)\n",
    "        - rate: float, e.g., 1.2 for 20% longer, 0.8 for 20% shorter\n",
    "        \"\"\"\n",
    "        rate = np.random.uniform(self.min_rate, self.max_rate)\n",
    "        L = x.shape[0]\n",
    "        L_new = int(L / rate)\n",
    "        orig_idx = np.linspace(0, L - 1, num=L)\n",
    "        new_idx = np.linspace(0, L - 1, num=L_new)\n",
    "\n",
    "        if x.ndim == 1:\n",
    "            return np.interp(new_idx, orig_idx, x)\n",
    "        elif x.ndim == 2:\n",
    "            return np.stack([\n",
    "                np.interp(new_idx, orig_idx, x[:, i]) for i in range(x.shape[1])\n",
    "            ], axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"Only 1D or 2D arrays are supported.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae24e69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.668381Z",
     "iopub.status.busy": "2025-08-18T13:13:06.668180Z",
     "iopub.status.idle": "2025-08-18T13:13:06.674015Z",
     "shell.execute_reply": "2025-08-18T13:13:06.673412Z"
    },
    "papermill": {
     "duration": 0.012969,
     "end_time": "2025-08-18T13:13:06.675136",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.662167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeShift(SignalTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, max_shift_pct=0.25, padding_mode=\"replace\"):\n",
    "        super().__init__(always_apply, p)\n",
    "        \n",
    "        assert 0 <= max_shift_pct <= 1.0, \"`max_shift_pct` must be between 0 and 1\"\n",
    "        assert padding_mode in [\"replace\", \"zero\"], \"`padding_mode` must be either 'replace' or 'zero'\"\n",
    "        \n",
    "        self.max_shift_pct = max_shift_pct\n",
    "        self.padding_mode = padding_mode\n",
    "\n",
    "    def apply(self, x: np.ndarray, **params):\n",
    "        assert x.ndim == 2, \"`x` must be a 2D array with shape (L, N)\"\n",
    "        \n",
    "        L = x.shape[0]\n",
    "        max_shift = int(L * self.max_shift_pct)\n",
    "        shift = np.random.randint(-max_shift, max_shift + 1)\n",
    "\n",
    "        # Roll along time axis (axis=0)\n",
    "        augmented = np.roll(x, shift, axis=0)\n",
    "\n",
    "        if self.padding_mode == \"zero\":\n",
    "            if shift > 0:\n",
    "                augmented[:shift, :] = 0\n",
    "            elif shift < 0:\n",
    "                augmented[shift:, :] = 0\n",
    "\n",
    "        return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b514836",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.687066Z",
     "iopub.status.busy": "2025-08-18T13:13:06.686534Z",
     "iopub.status.idle": "2025-08-18T13:13:06.692008Z",
     "shell.execute_reply": "2025-08-18T13:13:06.691188Z"
    },
    "papermill": {
     "duration": 0.012714,
     "end_time": "2025-08-18T13:13:06.693085",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.680371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ButterFilter(SignalTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "        super().__init__(always_apply, p)\n",
    "        \n",
    "        self.cutoff_freq = cutoff_freq\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.order = order\n",
    "\n",
    "    def apply(self, x: np.ndarray, **params):\n",
    "        assert x.ndim == 2, \"`x` must be a 2D array with shape (L, N)\"\n",
    "        return self.butter_lowpass_filter(x)\n",
    "\n",
    "    def butter_lowpass_filter(self, data: np.ndarray):\n",
    "        nyquist = 0.5 * self.sampling_rate\n",
    "        normal_cutoff = self.cutoff_freq / nyquist\n",
    "        b, a = butter(self.order, normal_cutoff, btype='low', analog=False)\n",
    "        filtered_data = lfilter(b, a, data, axis=0)  # filter each channel independently\n",
    "        return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2165c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.704127Z",
     "iopub.status.busy": "2025-08-18T13:13:06.703928Z",
     "iopub.status.idle": "2025-08-18T13:13:06.714841Z",
     "shell.execute_reply": "2025-08-18T13:13:06.714255Z"
    },
    "papermill": {
     "duration": 0.01756,
     "end_time": "2025-08-18T13:13:06.715823",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.698263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, config,df: pd.DataFrame, X: list[np.ndarray], y = None,\n",
    "        transforms = None, mode: str = \"train\"\n",
    "    ): \n",
    "        self.config = config\n",
    "        self.df = df\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.indexes = self.df.sequence_id.unique()\n",
    "        self.alpha = 0.3\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms\n",
    "        self.num_classes = 18\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length of dataset.\n",
    "        \"\"\"\n",
    "        return len(self.indexes)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        Get one item.\n",
    "        \"\"\"\n",
    "        sequence_id = self.indexes[i]\n",
    "        p = np.random.rand()\n",
    "        if p <= 0.0:\n",
    "            if self.mode == \"train\":\n",
    "                X, y = self.get_data(i)\n",
    "                X = self.transforms(X)\n",
    "                X = random_padding(X)\n",
    "                output = {\n",
    "                    \"X\": torch.tensor(X, dtype=torch.float32),\n",
    "                    \"y\": torch.tensor(y, dtype=torch.float32),\n",
    "                }\n",
    "            elif self.mode == \"test\":\n",
    "                X = self.get_data(i)\n",
    "                X = random_padding(X)\n",
    "                output = {\n",
    "                    \"X\": torch.tensor(X, dtype=torch.float32)\n",
    "                }\n",
    "            elif self.mode == \"val\":\n",
    "                X ,y= self.get_data(i)\n",
    "                X = random_padding(X)\n",
    "                output = {\n",
    "                    \"X\": torch.tensor(X, dtype=torch.float32),\n",
    "                    \"y\": torch.tensor(y, dtype=torch.float32)\n",
    "                }\n",
    "        else:\n",
    "            if self.mode == \"train\":\n",
    "                lam = np.random.beta(self.alpha, self.alpha)\n",
    "                j = np.random.randint(0, len(self.indexes))\n",
    "                X1, y1 = self.get_data(i)\n",
    "                X2, y2 = self.get_data(j)\n",
    "                X1, X2 = random_padding(X1), random_padding(X2) \n",
    "                X = lam * X1 + (1 - lam) * X2\n",
    "                y = lam * y1 + (1 - lam) * y2\n",
    "                output = {\n",
    "                    \"X\": torch.tensor(X, dtype=torch.float32),\n",
    "                    \"y\": torch.tensor(y, dtype=torch.float32),\n",
    "                }\n",
    "            elif self.mode == \"test\":\n",
    "                X = self.get_data(i)\n",
    "                X = random_padding(X)\n",
    "                output = {\n",
    "                    \"X\": torch.tensor(X, dtype=torch.float32)\n",
    "                }\n",
    "            elif self.mode == \"val\":\n",
    "                X ,y= self.get_data(i)\n",
    "                X = random_padding(X)\n",
    "                output = {\n",
    "                    \"X\": torch.tensor(X, dtype=torch.float32),\n",
    "                    \"y\": torch.tensor(y, dtype=torch.float32)\n",
    "                }\n",
    "                  \n",
    "        return output\n",
    "\n",
    "    def get_data(self, index):\n",
    "        X = self.X[index]\n",
    "        if self.mode in [\"train\",\"val\"]:\n",
    "            y = self.y[index]\n",
    "            y = np.eye(self.num_classes, dtype=int)[y]\n",
    "            return X, y\n",
    "        elif self.mode == \"test\":\n",
    "            return X\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85cac37e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.726757Z",
     "iopub.status.busy": "2025-08-18T13:13:06.726522Z",
     "iopub.status.idle": "2025-08-18T13:13:06.730600Z",
     "shell.execute_reply": "2025-08-18T13:13:06.729855Z"
    },
    "papermill": {
     "duration": 0.011369,
     "end_time": "2025-08-18T13:13:06.731938",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.720569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    OneOf([\n",
    "        GaussianNoise(p=0.5, max_noise_amplitude=0.05),\n",
    "        PinkNoiseSNR(p=0.5, min_snr=4.0, max_snr=20.0),\n",
    "        ButterFilter(p=0.5)\n",
    "    ]),\n",
    "    TimeStretch(p=0.25),\n",
    "    TimeShift(p=0.25)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4a2b366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.744199Z",
     "iopub.status.busy": "2025-08-18T13:13:06.743407Z",
     "iopub.status.idle": "2025-08-18T13:13:06.747120Z",
     "shell.execute_reply": "2025-08-18T13:13:06.746463Z"
    },
    "papermill": {
     "duration": 0.01087,
     "end_time": "2025-08-18T13:13:06.748289",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.737419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset = CustomDataset(config,train, train_X,  train_y, transforms, mode=\"train\")\n",
    "# val_dataset = CustomDataset(config,val, val_X,  val_y, mode=\"val\")\n",
    "test_dataset =  CustomDataset(config,df = df_test,X = test_X,mode=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65ec27db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.759929Z",
     "iopub.status.busy": "2025-08-18T13:13:06.759699Z",
     "iopub.status.idle": "2025-08-18T13:13:06.762838Z",
     "shell.execute_reply": "2025-08-18T13:13:06.762199Z"
    },
    "papermill": {
     "duration": 0.010368,
     "end_time": "2025-08-18T13:13:06.764051",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.753683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x = train_dataset.__getitem__(0)\n",
    "# x['X'].sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8706237f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.775459Z",
     "iopub.status.busy": "2025-08-18T13:13:06.775264Z",
     "iopub.status.idle": "2025-08-18T13:13:06.783071Z",
     "shell.execute_reply": "2025-08-18T13:13:06.782555Z"
    },
    "papermill": {
     "duration": 0.014747,
     "end_time": "2025-08-18T13:13:06.784097",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.769350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#(batch_size, seq_len, 7)\n",
    "class lstm(nn.Module):\n",
    "    def __init__(self,input_dim,num_layers):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=128, num_layers=num_layers, batch_first=True,bidirectional=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return out\n",
    "\n",
    "class conv(nn.Module):\n",
    "    def __init__(self,input_channels,output_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        self.convs= nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(output_channels)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        out = self.convs(x)\n",
    "        return out      \n",
    "        \n",
    "class lstm_res(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm1 = lstm(7,2)\n",
    "        self.conv1 = conv(1,128,5)\n",
    "        self.conv2 = conv(128,64,5)\n",
    "        self.conv3 = conv(1,64,1)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.Dense = nn.Sequential(nn.Linear(64, 32),nn.ReLU(),nn.Linear(32, 18))\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        lstm_out1 = self.lstm1(x)\n",
    "        conv_out1 = self.conv1(lstm_out1.unsqueeze(1))    ##dimension add for cnn layers\n",
    "        conv_out2 = self.conv2(conv_out1)\n",
    "        conv_out3 = self.conv3(lstm_out1.unsqueeze(1))\n",
    "\n",
    "        upsampled = F.interpolate(conv_out3, size=conv_out2.shape[2:], mode= 'nearest')\n",
    "\n",
    "        out = (conv_out2 + upsampled)\n",
    "        # out = conv_out2\n",
    "        out = self.avg_pool(out).view(out.shape[0],-1)\n",
    "\n",
    "        out = self.Dense(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "709fb168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.795395Z",
     "iopub.status.busy": "2025-08-18T13:13:06.795190Z",
     "iopub.status.idle": "2025-08-18T13:13:06.801057Z",
     "shell.execute_reply": "2025-08-18T13:13:06.800425Z"
    },
    "papermill": {
     "duration": 0.013066,
     "end_time": "2025-08-18T13:13:06.802176",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.789110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader,criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for p in train_loader:\n",
    "            \n",
    "            inputs = p['X'].to(device)            \n",
    "            targets = p['y'].to(device)      \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)              \n",
    "            loss = loss = criterion(F.log_softmax(outputs, dim=1), targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            # print(targets)\n",
    "            # print(predicted)\n",
    "            _,targets = torch.max(targets,1)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {total_loss:.4f}, Accuracy: {acc:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5201ba4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.813277Z",
     "iopub.status.busy": "2025-08-18T13:13:06.813065Z",
     "iopub.status.idle": "2025-08-18T13:13:06.817088Z",
     "shell.execute_reply": "2025-08-18T13:13:06.816500Z"
    },
    "papermill": {
     "duration": 0.010951,
     "end_time": "2025-08-18T13:13:06.818261",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.807310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# model = lstm_res()\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = model.to(device)\n",
    "\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.005)   \n",
    "# criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False) \n",
    "\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# train_model(model, train_loader, criterion, optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b34545ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.829689Z",
     "iopub.status.busy": "2025-08-18T13:13:06.829186Z",
     "iopub.status.idle": "2025-08-18T13:13:06.832499Z",
     "shell.execute_reply": "2025-08-18T13:13:06.831942Z"
    },
    "papermill": {
     "duration": 0.009975,
     "end_time": "2025-08-18T13:13:06.833548",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.823573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch, os\n",
    "\n",
    "# save_dir = \"/kaggle/working\"\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "# model_path = os.path.join(save_dir, \"lstm_res_005_64.pth\")\n",
    "# torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# # optionally save optimizer + epoch as checkpoint\n",
    "# checkpoint = {\n",
    "#     \"model_state\": model.state_dict(),\n",
    "#     \"optimizer_state\": optimizer.state_dict()\n",
    "# }\n",
    "# torch.save(checkpoint, os.path.join(save_dir, model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25336ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:06.845267Z",
     "iopub.status.busy": "2025-08-18T13:13:06.844629Z",
     "iopub.status.idle": "2025-08-18T13:13:07.369774Z",
     "shell.execute_reply": "2025-08-18T13:13:07.368932Z"
    },
    "papermill": {
     "duration": 0.53274,
     "end_time": "2025-08-18T13:13:07.371274",
     "exception": false,
     "start_time": "2025-08-18T13:13:06.838534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "model = lstm_res().to(device)\n",
    "ckpt = torch.load(\"/kaggle/input/lstm_latest/pytorch/default/1/lstm_res_005_64.pth\", map_location=device)['model_state']\n",
    "model.load_state_dict(ckpt)\n",
    "model.eval()\n",
    "\n",
    "# --- Batch prediction function (for a DataLoader) ---\n",
    "def predict_imu(model, loader, device=device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if isinstance(batch, dict):\n",
    "                X = batch['X'].to(device)\n",
    "            elif isinstance(batch, (list, tuple)):\n",
    "                X = batch[0].to(device)\n",
    "            else:\n",
    "                X = batch.to(device)\n",
    "\n",
    "            logits = model(X)\n",
    "            preds = torch.argmax(logits, dim=1)  \n",
    "            all_preds.append(preds.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "    return all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6e6d822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:07.383276Z",
     "iopub.status.busy": "2025-08-18T13:13:07.382610Z",
     "iopub.status.idle": "2025-08-18T13:13:07.386272Z",
     "shell.execute_reply": "2025-08-18T13:13:07.385645Z"
    },
    "papermill": {
     "duration": 0.010464,
     "end_time": "2025-08-18T13:13:07.387410",
     "exception": false,
     "start_time": "2025-08-18T13:13:07.376946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict_val = predict_imu(model, val_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d578c378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:07.398973Z",
     "iopub.status.busy": "2025-08-18T13:13:07.398401Z",
     "iopub.status.idle": "2025-08-18T13:13:07.402208Z",
     "shell.execute_reply": "2025-08-18T13:13:07.401437Z"
    },
    "papermill": {
     "duration": 0.01068,
     "end_time": "2025-08-18T13:13:07.403308",
     "exception": false,
     "start_time": "2025-08-18T13:13:07.392628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# acc = accuracy_score(val_y, predict_val)\n",
    "# print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4907e65d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:07.414060Z",
     "iopub.status.busy": "2025-08-18T13:13:07.413801Z",
     "iopub.status.idle": "2025-08-18T13:13:07.418507Z",
     "shell.execute_reply": "2025-08-18T13:13:07.417758Z"
    },
    "papermill": {
     "duration": 0.011585,
     "end_time": "2025-08-18T13:13:07.419846",
     "exception": false,
     "start_time": "2025-08-18T13:13:07.408261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd.crosstab(val_y,predict_val)\n",
    "# print(np.unique(val_y))\n",
    "# print(np.unique(predict_val))\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def ScoreMetric(ytrue, ypreds)-> tuple:\n",
    "    bscore = f1_score(\n",
    "        np.where(ytrue  <= 7, 1, 0),\n",
    "        np.where(ypreds <= 7, 1, 0),\n",
    "        zero_division = 0.0,\n",
    "    )\n",
    "\n",
    "    mscore = f1_score(\n",
    "        np.where(ytrue   <= 7, ytrue, 99),\n",
    "        np.where(ypreds  <= 7, ypreds, 99),\n",
    "        average = \"macro\", \n",
    "        zero_division = 0.0,\n",
    "    )\n",
    "\n",
    "    return (0.5 * (bscore + mscore))\n",
    "\n",
    "# ScoreMetric(val_y,predict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33330cf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:07.431441Z",
     "iopub.status.busy": "2025-08-18T13:13:07.431237Z",
     "iopub.status.idle": "2025-08-18T13:13:07.434633Z",
     "shell.execute_reply": "2025-08-18T13:13:07.433915Z"
    },
    "papermill": {
     "duration": 0.010543,
     "end_time": "2025-08-18T13:13:07.435814",
     "exception": false,
     "start_time": "2025-08-18T13:13:07.425271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(model, \"/kaggle/working/lstm_res_full.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2935bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:07.446831Z",
     "iopub.status.busy": "2025-08-18T13:13:07.446568Z",
     "iopub.status.idle": "2025-08-18T13:13:11.361947Z",
     "shell.execute_reply": "2025-08-18T13:13:11.360980Z"
    },
    "papermill": {
     "duration": 3.922238,
     "end_time": "2025-08-18T13:13:11.363275",
     "exception": false,
     "start_time": "2025-08-18T13:13:07.441037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 582.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 606.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import polars as pl\n",
    "import kaggle_evaluation.cmi_inference_server\n",
    "from collections import Counter\n",
    "cols = df_test.columns\n",
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    test_X = []\n",
    "    sequence = pd.DataFrame(sequence)\n",
    "    sequence.columns = cols\n",
    "    # print(sequence)\n",
    "    sequence_ids_test = sequence.sequence_id.unique()\n",
    "    \n",
    "    for sequence_id in tqdm(sequence_ids_test):\n",
    "        ds = sequence[sequence[\"sequence_id\"] == sequence_id]\n",
    "        X = ds[imu_cols].to_numpy(dtype=np.float32)\n",
    "        # print(X.dtype)\n",
    "        acc = standard_scale(X[:, 0:3])\n",
    "        rot = X[:, 3:]\n",
    "        X = np.concatenate([acc, rot], axis=1)\n",
    "        X = np.where(np.isnan(X),0, X)  # fill NaNs\n",
    "        test_X.append(X)\n",
    "\n",
    "    test_seq = CustomDataset(config,df = sequence,X = test_X,mode=\"test\")\n",
    "    test_loader = DataLoader(test_seq, batch_size=64, shuffle=True)\n",
    "    predictions = predict_imu(model,test_loader,device)\n",
    "    pred = num_to_label[predictions[0]]\n",
    "    return str(pred)\n",
    "\n",
    "\n",
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "# inference_server.serve()\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4f12c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:13:11.376322Z",
     "iopub.status.busy": "2025-08-18T13:13:11.375903Z",
     "iopub.status.idle": "2025-08-18T13:13:11.443705Z",
     "shell.execute_reply": "2025-08-18T13:13:11.442905Z"
    },
    "papermill": {
     "duration": 0.07529,
     "end_time": "2025-08-18T13:13:11.444729",
     "exception": false,
     "start_time": "2025-08-18T13:13:11.369439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running manual test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 571.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual prediction result for sequence_id SEQ_000001: Cheek - pinch skin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    print(\"\\nRunning manual test...\")\n",
    "    test_df = pd.read_csv('/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv')\n",
    "    demographics = pd.read_csv('/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv')\n",
    "    sample_seq_id = \"SEQ_000001\"\n",
    "    test_seq = test_df[test_df['sequence_id'] == sample_seq_id]\n",
    "    prediction = predict(pl.DataFrame(test_seq), pl.DataFrame(demographics))\n",
    "    print(f\"Manual prediction result for sequence_id {sample_seq_id}: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985b02f",
   "metadata": {
    "papermill": {
     "duration": 0.005276,
     "end_time": "2025-08-18T13:13:11.455430",
     "exception": false,
     "start_time": "2025-08-18T13:13:11.450154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9843e5",
   "metadata": {
    "papermill": {
     "duration": 0.005325,
     "end_time": "2025-08-18T13:13:11.465852",
     "exception": false,
     "start_time": "2025-08-18T13:13:11.460527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 8091067,
     "sourceId": 12797297,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 429926,
     "modelInstanceId": 412140,
     "sourceId": 525330,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 430432,
     "modelInstanceId": 412669,
     "sourceId": 527044,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 60.103288,
   "end_time": "2025-08-18T13:13:14.416396",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-18T13:12:14.313108",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
