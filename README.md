<img width="1071" height="441" alt="image" src="https://github.com/user-attachments/assets/2b57b355-0b32-40ca-b74d-513a9d9e9192" /><img width="1071" height="441" alt="image" src="https://github.com/user-attachments/assets/d015721c-e657-47b8-ba37-4113bb9c8f33" /># Hand Gesture recognition using IMU sensors data

Classify 18 different had gestures based on imu sensor data coming from a wrist worn device by people.Data also consists of demographic information about the subjects like: age, sex, Dominant hand used by the participant(0 = left-handed, 1 = right-handed),height,Distance from shoulder to wrist, Distance from elbow to wrist etc.

The notebook implements following paper's model architecture from scratch with some additional data preprocessings.

The model architecture is shown below:

<img width="1071" height="441" alt="image" src="https://github.com/user-attachments/assets/9a080749-36e1-4040-857b-4425c76c55e0" />

